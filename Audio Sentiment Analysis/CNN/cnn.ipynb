{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, MaxPooling1D, Flatten, Dense, LeakyReLU, Layer, AveragePooling1D,Conv1D,ELU\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "from keras.regularizers import l2\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"combinedfilepaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>SAVEE/DC_a01.wav</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>SAVEE/DC_a02.wav</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>SAVEE/DC_a03.wav</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>SAVEE/DC_a04.wav</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>SAVEE/DC_a05.wav</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>1435</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>RAVEDESS/audio_speech_actors_01-24/Actor_24/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11298</th>\n",
       "      <td>1436</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>RAVEDESS/audio_speech_actors_01-24/Actor_24/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>1437</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>RAVEDESS/audio_speech_actors_01-24/Actor_24/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11300</th>\n",
       "      <td>1438</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>RAVEDESS/audio_speech_actors_01-24/Actor_24/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>1439</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>RAVEDESS/audio_speech_actors_01-24/Actor_24/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11302 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Emotion  \\\n",
       "0               0   Disgust   \n",
       "1               1   Disgust   \n",
       "2               2   Disgust   \n",
       "3               3   Disgust   \n",
       "4               4   Disgust   \n",
       "...           ...       ...   \n",
       "11297        1435  Surprise   \n",
       "11298        1436  Surprise   \n",
       "11299        1437  Surprise   \n",
       "11300        1438  Surprise   \n",
       "11301        1439  Surprise   \n",
       "\n",
       "                                                    Path  Gender  \n",
       "0                                       SAVEE/DC_a01.wav    Male  \n",
       "1                                       SAVEE/DC_a02.wav    Male  \n",
       "2                                       SAVEE/DC_a03.wav    Male  \n",
       "3                                       SAVEE/DC_a04.wav    Male  \n",
       "4                                       SAVEE/DC_a05.wav    Male  \n",
       "...                                                  ...     ...  \n",
       "11297  RAVEDESS/audio_speech_actors_01-24/Actor_24/03...  Female  \n",
       "11298  RAVEDESS/audio_speech_actors_01-24/Actor_24/03...  Female  \n",
       "11299  RAVEDESS/audio_speech_actors_01-24/Actor_24/03...  Female  \n",
       "11300  RAVEDESS/audio_speech_actors_01-24/Actor_24/03...  Female  \n",
       "11301  RAVEDESS/audio_speech_actors_01-24/Actor_24/03...  Female  \n",
       "\n",
       "[11302 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(signal):\n",
    "    \"Adds random Gaussian noise to a signal.\"\n",
    "    amplitude = 0.035 * np.random.uniform() * np.amax(signal)\n",
    "    noise = amplitude * np.random.normal(size=signal.shape[0])\n",
    "    noisy_signal = signal + noise\n",
    "    return noisy_signal\n",
    "\n",
    "def time_stretch(signal, rate=0.8):\n",
    "    \"Applies time stretching to a signal.\"\n",
    "    stretched_signal = librosa.effects.time_stretch(signal, rate=rate)\n",
    "    return stretched_signal\n",
    "\n",
    "def pitch_shift(signal, sampling_rate, pitch_factor=0.7):\n",
    "    \"Applies pitch shifting to a signal.\"\n",
    "    shifted_signal = librosa.effects.pitch_shift(signal, sr=sampling_rate, n_steps=pitch_factor)\n",
    "    return shifted_signal\n",
    "\n",
    "def speed_change(signal, sampling_rate, speed_factor=0.7):\n",
    "    \"Applies speed change to a signal.\"\n",
    "    new_sampling_rate = int(sampling_rate * speed_factor)\n",
    "    resampled_signal = librosa.resample(signal, orig_sr=sampling_rate, target_sr=new_sampling_rate)\n",
    "    return resampled_signal\n",
    "\n",
    "def time_shift(signal):\n",
    "    \"Shifts the signal by a random number of samples.\"\n",
    "    shift_range = int(np.random.uniform(low=-5, high=5) * 1000)\n",
    "    shifted_signal = np.roll(signal, shift_range)\n",
    "    return shifted_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_methods(data,sample_rate):\n",
    "    # Zero Crossing\n",
    "    feature = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    feature=np.hstack((feature, zcr))\n",
    "\n",
    "    # Chroma\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    feature = np.hstack((feature, chroma_stft))\n",
    "\n",
    "    # MFCC Base\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    feature = np.hstack((feature, mfcc))\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    feature = np.hstack((feature, rms))\n",
    "\n",
    "    # Mel Spectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    feature = np.hstack((feature, mel)) \n",
    "\n",
    "    #Spectral Contrast\n",
    "    spectral=np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T, axis=0)\n",
    "    feature= np.hstack((feature,spectral))\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "\n",
    "    res1 = feature_methods(data,sample_rate)\n",
    "    feature = np.array(res1)\n",
    "    \n",
    "    noise_data = add_noise(data)\n",
    "    res2 = feature_methods(noise_data,sample_rate)\n",
    "    feature = np.vstack((feature, res2))\n",
    "    \n",
    "    new_data = time_stretch(data)\n",
    "    data_stretch_pitch = pitch_shift(new_data, sample_rate)\n",
    "    res3 = feature_methods(data_stretch_pitch,sample_rate)\n",
    "    feature = np.vstack((feature, res3))\n",
    "\n",
    "    #noise_data = noise(data)\n",
    "    #sped_up_data=speed(noise_data,sample_rate)\n",
    "    #res4 = feature_methods(sped_up_data)\n",
    "    #feature = np.vstack((feature, res4))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\librosa\\core\\pitch.py:102: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(df.Path, df.Emotion):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038891</td>\n",
       "      <td>0.470762</td>\n",
       "      <td>0.580041</td>\n",
       "      <td>0.556164</td>\n",
       "      <td>0.485299</td>\n",
       "      <td>0.460506</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.506228</td>\n",
       "      <td>0.460546</td>\n",
       "      <td>0.536092</td>\n",
       "      <td>...</td>\n",
       "      <td>6.204343e-07</td>\n",
       "      <td>1.810680e-07</td>\n",
       "      <td>30.325378</td>\n",
       "      <td>19.403687</td>\n",
       "      <td>21.866991</td>\n",
       "      <td>19.155308</td>\n",
       "      <td>22.740866</td>\n",
       "      <td>19.702703</td>\n",
       "      <td>50.953309</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074024</td>\n",
       "      <td>0.564610</td>\n",
       "      <td>0.669950</td>\n",
       "      <td>0.660861</td>\n",
       "      <td>0.596096</td>\n",
       "      <td>0.573729</td>\n",
       "      <td>0.565783</td>\n",
       "      <td>0.569342</td>\n",
       "      <td>0.542778</td>\n",
       "      <td>0.600784</td>\n",
       "      <td>...</td>\n",
       "      <td>2.699842e-02</td>\n",
       "      <td>2.621805e-02</td>\n",
       "      <td>24.214328</td>\n",
       "      <td>18.093431</td>\n",
       "      <td>19.081227</td>\n",
       "      <td>14.339408</td>\n",
       "      <td>15.280328</td>\n",
       "      <td>13.821124</td>\n",
       "      <td>13.617951</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.337834</td>\n",
       "      <td>0.433951</td>\n",
       "      <td>0.576598</td>\n",
       "      <td>0.553174</td>\n",
       "      <td>0.446085</td>\n",
       "      <td>0.431478</td>\n",
       "      <td>0.449681</td>\n",
       "      <td>0.458042</td>\n",
       "      <td>0.448164</td>\n",
       "      <td>...</td>\n",
       "      <td>3.287237e-07</td>\n",
       "      <td>6.452242e-08</td>\n",
       "      <td>33.409295</td>\n",
       "      <td>19.594216</td>\n",
       "      <td>22.811201</td>\n",
       "      <td>20.137145</td>\n",
       "      <td>22.575847</td>\n",
       "      <td>20.587578</td>\n",
       "      <td>52.658367</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033904</td>\n",
       "      <td>0.662605</td>\n",
       "      <td>0.704369</td>\n",
       "      <td>0.623005</td>\n",
       "      <td>0.550529</td>\n",
       "      <td>0.483566</td>\n",
       "      <td>0.450042</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>0.463125</td>\n",
       "      <td>0.555203</td>\n",
       "      <td>...</td>\n",
       "      <td>3.427215e-05</td>\n",
       "      <td>8.903367e-06</td>\n",
       "      <td>30.483110</td>\n",
       "      <td>19.709231</td>\n",
       "      <td>20.306943</td>\n",
       "      <td>18.802990</td>\n",
       "      <td>21.573450</td>\n",
       "      <td>19.994558</td>\n",
       "      <td>50.950351</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.671452</td>\n",
       "      <td>0.723635</td>\n",
       "      <td>0.643924</td>\n",
       "      <td>0.571611</td>\n",
       "      <td>0.498932</td>\n",
       "      <td>0.456688</td>\n",
       "      <td>0.431968</td>\n",
       "      <td>0.472708</td>\n",
       "      <td>0.568428</td>\n",
       "      <td>...</td>\n",
       "      <td>7.383929e-05</td>\n",
       "      <td>4.553373e-05</td>\n",
       "      <td>30.263579</td>\n",
       "      <td>19.300359</td>\n",
       "      <td>20.366364</td>\n",
       "      <td>18.683943</td>\n",
       "      <td>20.774781</td>\n",
       "      <td>16.853630</td>\n",
       "      <td>15.156141</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33901</th>\n",
       "      <td>0.300505</td>\n",
       "      <td>0.651378</td>\n",
       "      <td>0.701116</td>\n",
       "      <td>0.714198</td>\n",
       "      <td>0.727364</td>\n",
       "      <td>0.769482</td>\n",
       "      <td>0.739211</td>\n",
       "      <td>0.673986</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.613899</td>\n",
       "      <td>...</td>\n",
       "      <td>4.983070e-03</td>\n",
       "      <td>1.282424e-03</td>\n",
       "      <td>10.969579</td>\n",
       "      <td>16.594378</td>\n",
       "      <td>16.770425</td>\n",
       "      <td>15.153919</td>\n",
       "      <td>15.643397</td>\n",
       "      <td>15.031598</td>\n",
       "      <td>14.076088</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33902</th>\n",
       "      <td>0.204243</td>\n",
       "      <td>0.627787</td>\n",
       "      <td>0.613118</td>\n",
       "      <td>0.618267</td>\n",
       "      <td>0.605335</td>\n",
       "      <td>0.571726</td>\n",
       "      <td>0.578201</td>\n",
       "      <td>0.638326</td>\n",
       "      <td>0.602793</td>\n",
       "      <td>0.534584</td>\n",
       "      <td>...</td>\n",
       "      <td>6.800647e-04</td>\n",
       "      <td>7.661296e-05</td>\n",
       "      <td>15.345251</td>\n",
       "      <td>20.605145</td>\n",
       "      <td>20.267049</td>\n",
       "      <td>18.771864</td>\n",
       "      <td>20.714421</td>\n",
       "      <td>19.669644</td>\n",
       "      <td>48.424924</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33903</th>\n",
       "      <td>0.219971</td>\n",
       "      <td>0.676553</td>\n",
       "      <td>0.613857</td>\n",
       "      <td>0.591720</td>\n",
       "      <td>0.571173</td>\n",
       "      <td>0.551790</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.585875</td>\n",
       "      <td>0.636384</td>\n",
       "      <td>0.642514</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115113e-03</td>\n",
       "      <td>9.113738e-05</td>\n",
       "      <td>14.712547</td>\n",
       "      <td>19.291330</td>\n",
       "      <td>18.095408</td>\n",
       "      <td>16.338751</td>\n",
       "      <td>17.601353</td>\n",
       "      <td>17.305378</td>\n",
       "      <td>45.689599</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>0.339925</td>\n",
       "      <td>0.721558</td>\n",
       "      <td>0.731098</td>\n",
       "      <td>0.741562</td>\n",
       "      <td>0.735407</td>\n",
       "      <td>0.739121</td>\n",
       "      <td>0.691160</td>\n",
       "      <td>0.667546</td>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.718491</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833119e-03</td>\n",
       "      <td>3.924944e-03</td>\n",
       "      <td>10.843671</td>\n",
       "      <td>15.000229</td>\n",
       "      <td>16.249062</td>\n",
       "      <td>14.312100</td>\n",
       "      <td>14.676303</td>\n",
       "      <td>14.194808</td>\n",
       "      <td>13.765681</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33905</th>\n",
       "      <td>0.190932</td>\n",
       "      <td>0.694790</td>\n",
       "      <td>0.649580</td>\n",
       "      <td>0.603220</td>\n",
       "      <td>0.587356</td>\n",
       "      <td>0.556304</td>\n",
       "      <td>0.523657</td>\n",
       "      <td>0.585494</td>\n",
       "      <td>0.620109</td>\n",
       "      <td>0.681985</td>\n",
       "      <td>...</td>\n",
       "      <td>3.580257e-04</td>\n",
       "      <td>2.698177e-05</td>\n",
       "      <td>16.504694</td>\n",
       "      <td>21.069536</td>\n",
       "      <td>20.123703</td>\n",
       "      <td>17.599874</td>\n",
       "      <td>19.587740</td>\n",
       "      <td>19.097080</td>\n",
       "      <td>48.758281</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33906 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.038891  0.470762  0.580041  0.556164  0.485299  0.460506  0.484227   \n",
       "1      0.074024  0.564610  0.669950  0.660861  0.596096  0.573729  0.565783   \n",
       "2      0.036010  0.337834  0.433951  0.576598  0.553174  0.446085  0.431478   \n",
       "3      0.033904  0.662605  0.704369  0.623005  0.550529  0.483566  0.450042   \n",
       "4      0.033868  0.671452  0.723635  0.643924  0.571611  0.498932  0.456688   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "33901  0.300505  0.651378  0.701116  0.714198  0.727364  0.769482  0.739211   \n",
       "33902  0.204243  0.627787  0.613118  0.618267  0.605335  0.571726  0.578201   \n",
       "33903  0.219971  0.676553  0.613857  0.591720  0.571173  0.551790  0.565728   \n",
       "33904  0.339925  0.721558  0.731098  0.741562  0.735407  0.739121  0.691160   \n",
       "33905  0.190932  0.694790  0.649580  0.603220  0.587356  0.556304  0.523657   \n",
       "\n",
       "              7         8         9  ...           160           161  \\\n",
       "0      0.506228  0.460546  0.536092  ...  6.204343e-07  1.810680e-07   \n",
       "1      0.569342  0.542778  0.600784  ...  2.699842e-02  2.621805e-02   \n",
       "2      0.449681  0.458042  0.448164  ...  3.287237e-07  6.452242e-08   \n",
       "3      0.422957  0.463125  0.555203  ...  3.427215e-05  8.903367e-06   \n",
       "4      0.431968  0.472708  0.568428  ...  7.383929e-05  4.553373e-05   \n",
       "...         ...       ...       ...  ...           ...           ...   \n",
       "33901  0.673986  0.614042  0.613899  ...  4.983070e-03  1.282424e-03   \n",
       "33902  0.638326  0.602793  0.534584  ...  6.800647e-04  7.661296e-05   \n",
       "33903  0.585875  0.636384  0.642514  ...  1.115113e-03  9.113738e-05   \n",
       "33904  0.667546  0.696196  0.718491  ...  4.833119e-03  3.924944e-03   \n",
       "33905  0.585494  0.620109  0.681985  ...  3.580257e-04  2.698177e-05   \n",
       "\n",
       "             162        163        164        165        166        167  \\\n",
       "0      30.325378  19.403687  21.866991  19.155308  22.740866  19.702703   \n",
       "1      24.214328  18.093431  19.081227  14.339408  15.280328  13.821124   \n",
       "2      33.409295  19.594216  22.811201  20.137145  22.575847  20.587578   \n",
       "3      30.483110  19.709231  20.306943  18.802990  21.573450  19.994558   \n",
       "4      30.263579  19.300359  20.366364  18.683943  20.774781  16.853630   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "33901  10.969579  16.594378  16.770425  15.153919  15.643397  15.031598   \n",
       "33902  15.345251  20.605145  20.267049  18.771864  20.714421  19.669644   \n",
       "33903  14.712547  19.291330  18.095408  16.338751  17.601353  17.305378   \n",
       "33904  10.843671  15.000229  16.249062  14.312100  14.676303  14.194808   \n",
       "33905  16.504694  21.069536  20.123703  17.599874  19.587740  19.097080   \n",
       "\n",
       "             168   Emotion  \n",
       "0      50.953309   Disgust  \n",
       "1      13.617951   Disgust  \n",
       "2      52.658367   Disgust  \n",
       "3      50.950351   Disgust  \n",
       "4      15.156141   Disgust  \n",
       "...          ...       ...  \n",
       "33901  14.076088  Surprise  \n",
       "33902  48.424924  Surprise  \n",
       "33903  45.689599  Surprise  \n",
       "33904  13.765681  Surprise  \n",
       "33905  48.758281  Surprise  \n",
       "\n",
       "[33906 rows x 170 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['Emotion'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features=pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25429, 169), (25429, 8), (8477, 169), (8477, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['Emotion'].values\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(encoder, 'encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "X_train = scaler.transform(x_train)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=np.sqrt(scaler.var_)\n",
    "np.save('std.npy',std)\n",
    "np.save('mean.npy',scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25429, 169, 1), (25429, 8), (8477, 169, 1), (8477, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 169, 128)          512       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 169, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 169, 128)          0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 169, 128)          49280     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 169, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 169, 128)          0         \n",
      "                                                                 \n",
      " average_pooling1d_4 (Averag  (None, 84, 128)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 84, 128)           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 84, 256)           98560     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 84, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 84, 256)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 84, 256)           196864    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 84, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 84, 256)           0         \n",
      "                                                                 \n",
      " average_pooling1d_5 (Averag  (None, 42, 256)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 42, 256)           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 42, 512)           393728    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 42, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 42, 512)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 42, 512)           786944    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 42, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 42, 512)           0         \n",
      "                                                                 \n",
      " average_pooling1d_6 (Averag  (None, 21, 512)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 21, 512)           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 21, 1024)          1573888   \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 21, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 21, 1024)          0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 21, 1024)          3146752   \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 21, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 21, 1024)          0         \n",
      "                                                                 \n",
      " average_pooling1d_7 (Averag  (None, 10, 1024)         0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 10, 1024)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10240)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               5243392   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,641,736\n",
      "Trainable params: 11,632,520\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "#Model with more layers/ Average pooling/ Leaky Relu Accuracy 82.04% Loss 0.7337\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same', input_shape=(x_train.shape[1],1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, x_train.shape[1], 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1_architecture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 169, 128)          512       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 169, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 169, 128)          0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 169, 128)          49280     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 169, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 169, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 84, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 84, 128)           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 84, 256)           98560     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 84, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 84, 256)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 84, 256)           196864    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 84, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 84, 256)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 42, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 42, 256)           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 42, 512)           393728    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 42, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 42, 512)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 42, 512)           786944    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 42, 512)          2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 42, 512)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 21, 512)           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 21, 1024)          1573888   \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 21, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 21, 1024)          0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 21, 1024)          3146752   \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 21, 1024)         4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 21, 1024)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 10, 1024)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 10, 1024)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10240)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               5243392   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,641,736\n",
      "Trainable params: 11,632,520\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "#Model with more layers/ Max pooling/ Leaky Relu Accuracy 78.8%, Loss 0.789 \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same', input_shape=(x_train.shape[1],1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, x_train.shape[1], 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2_architecture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 169, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 169, 256)          1536      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 169, 256)          0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 169, 256)          327936    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 169, 256)         1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 169, 256)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 169, 256)          0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 21, 128)           163968    \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 21, 128)           82048     \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 21, 128)           82048     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 21, 128)           82048     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 21, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 21, 128)           0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 21, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 2, 64)             41024     \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 2, 64)             0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 2, 64)             20544     \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 2, 64)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 803,720\n",
      "Trainable params: 802,952\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "#Base Model using Functional API 64.4%\n",
    "input_layer = Input(shape=(x_train.shape[1], 1))\n",
    "\n",
    "conv_layer_1 = Conv1D(256, 5, padding='same')(input_layer)\n",
    "activation_layer_1 = Activation('relu')(conv_layer_1)\n",
    "\n",
    "conv_layer_2 = Conv1D(256, 5, padding='same')(activation_layer_1)\n",
    "batch_norm_layer_1 = BatchNormalization()(conv_layer_2)\n",
    "activation_layer_2 = Activation('relu')(batch_norm_layer_1)\n",
    "dropout_layer_1 = Dropout(0.2)(activation_layer_2)\n",
    "max_pooling_layer_1 = MaxPooling1D(pool_size=(8))(dropout_layer_1)\n",
    "\n",
    "conv_layer_3 = Conv1D(128, 5, padding='same')(max_pooling_layer_1)\n",
    "activation_layer_3 = Activation('relu')(conv_layer_3)\n",
    "\n",
    "conv_layer_4 = Conv1D(128, 5, padding='same')(activation_layer_3)\n",
    "activation_layer_4 = Activation('relu')(conv_layer_4)\n",
    "\n",
    "conv_layer_5 = Conv1D(128, 5, padding='same')(activation_layer_4)\n",
    "activation_layer_5 = Activation('relu')(conv_layer_5)\n",
    "\n",
    "conv_layer_6 = Conv1D(128, 5, padding='same')(activation_layer_5)\n",
    "batch_norm_layer_2 = BatchNormalization()(conv_layer_6)\n",
    "activation_layer_6 = Activation('relu')(batch_norm_layer_2)\n",
    "dropout_layer_2 = Dropout(0.2)(activation_layer_6)\n",
    "max_pooling_layer_2 = MaxPooling1D(pool_size=(8))(dropout_layer_2)\n",
    "\n",
    "conv_layer_7 = Conv1D(64, 5, padding='same')(max_pooling_layer_2)\n",
    "activation_layer_7 = Activation('relu')(conv_layer_7)\n",
    "\n",
    "conv_layer_8 = Conv1D(64, 5, padding='same')(activation_layer_7)\n",
    "activation_layer_8 = Activation('relu')(conv_layer_8)\n",
    "\n",
    "flatten_layer = Flatten()(activation_layer_8)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(flatten_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "module_wrapper (ModuleWrappe (None, 169, 128)          512       \n",
      "_________________________________________________________________\n",
      "module_wrapper_1 (ModuleWrap (None, 169, 128)          512       \n",
      "_________________________________________________________________\n",
      "module_wrapper_2 (ModuleWrap (None, 169, 128)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_3 (ModuleWrap (None, 169, 128)          49280     \n",
      "_________________________________________________________________\n",
      "module_wrapper_4 (ModuleWrap (None, 169, 128)          512       \n",
      "_________________________________________________________________\n",
      "module_wrapper_5 (ModuleWrap (None, 169, 128)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_6 (ModuleWrap (None, 84, 128)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_7 (ModuleWrap (None, 84, 128)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_8 (ModuleWrap (None, 84, 256)           98560     \n",
      "_________________________________________________________________\n",
      "module_wrapper_9 (ModuleWrap (None, 84, 256)           1024      \n",
      "_________________________________________________________________\n",
      "module_wrapper_10 (ModuleWra (None, 84, 256)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_11 (ModuleWra (None, 84, 256)           196864    \n",
      "_________________________________________________________________\n",
      "module_wrapper_12 (ModuleWra (None, 84, 256)           1024      \n",
      "_________________________________________________________________\n",
      "module_wrapper_13 (ModuleWra (None, 84, 256)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_14 (ModuleWra (None, 42, 256)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_15 (ModuleWra (None, 42, 256)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_16 (ModuleWra (None, 42, 512)           393728    \n",
      "_________________________________________________________________\n",
      "module_wrapper_17 (ModuleWra (None, 42, 512)           2048      \n",
      "_________________________________________________________________\n",
      "module_wrapper_18 (ModuleWra (None, 42, 512)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_19 (ModuleWra (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "module_wrapper_20 (ModuleWra (None, 42, 512)           2048      \n",
      "_________________________________________________________________\n",
      "module_wrapper_21 (ModuleWra (None, 42, 512)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_22 (ModuleWra (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_23 (ModuleWra (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_24 (ModuleWra (None, 21, 1024)          1573888   \n",
      "_________________________________________________________________\n",
      "module_wrapper_25 (ModuleWra (None, 21, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "module_wrapper_26 (ModuleWra (None, 21, 1024)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_27 (ModuleWra (None, 21, 1024)          3146752   \n",
      "_________________________________________________________________\n",
      "module_wrapper_28 (ModuleWra (None, 21, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "module_wrapper_29 (ModuleWra (None, 21, 1024)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_30 (ModuleWra (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_31 (ModuleWra (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_32 (ModuleWra (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_33 (ModuleWra (None, 512)               5243392   \n",
      "_________________________________________________________________\n",
      "module_wrapper_34 (ModuleWra (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "module_wrapper_35 (ModuleWra (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_36 (ModuleWra (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_37 (ModuleWra (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "module_wrapper_38 (ModuleWra (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "module_wrapper_39 (ModuleWra (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_40 (ModuleWra (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_41 (ModuleWra (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 11,641,736\n",
      "Trainable params: 11,632,520\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 4\n",
    "#ELU Accuracy 40% Loss 2.054\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same', input_shape=(x_train.shape[1],1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "\n",
    "model.add(Conv1D(512, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "\n",
    "model.add(Conv1D(1024, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU(alpha=1.0))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, x_train.shape[1], 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', save_best_only=False):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best = float('inf') if save_best_only else None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "        if self.save_best_only:\n",
    "            current = logs.get(self.monitor)\n",
    "            if current is None:\n",
    "                pass\n",
    "            elif current < self.best:\n",
    "                self.best = current\n",
    "                self.model.save_weights(filepath, overwrite=True)\n",
    "        else:\n",
    "            self.model.save_weights(filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  6/398 [..............................] - ETA: 18s - loss: 1.8092 - accuracy: 0.2943WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0269s vs `on_train_batch_end` time: 0.0386s). Check your callbacks.\n",
      "398/398 [==============================] - 15s 38ms/step - loss: 1.5871 - accuracy: 0.3656 - val_loss: 1.8007 - val_accuracy: 0.3453 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 13s 34ms/step - loss: 1.3975 - accuracy: 0.4451 - val_loss: 1.3745 - val_accuracy: 0.4589 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 18s 46ms/step - loss: 1.3017 - accuracy: 0.4811 - val_loss: 1.4620 - val_accuracy: 0.4525 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 21s 52ms/step - loss: 1.2518 - accuracy: 0.5016 - val_loss: 2.2096 - val_accuracy: 0.3040 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 21s 52ms/step - loss: 1.2209 - accuracy: 0.5122 - val_loss: 2.0094 - val_accuracy: 0.3134 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 26s 65ms/step - loss: 1.1930 - accuracy: 0.5249 - val_loss: 1.1992 - val_accuracy: 0.5224 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 1.1666 - accuracy: 0.5318 - val_loss: 1.3861 - val_accuracy: 0.4523 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 21s 52ms/step - loss: 1.1482 - accuracy: 0.5403 - val_loss: 2.4041 - val_accuracy: 0.3278 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 21s 53ms/step - loss: 1.1236 - accuracy: 0.5470 - val_loss: 1.1304 - val_accuracy: 0.5505 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 26s 65ms/step - loss: 1.1045 - accuracy: 0.5603 - val_loss: 1.1165 - val_accuracy: 0.5503 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 25s 64ms/step - loss: 1.0877 - accuracy: 0.5685 - val_loss: 2.3003 - val_accuracy: 0.2994 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 1.0722 - accuracy: 0.5727 - val_loss: 1.2350 - val_accuracy: 0.5061 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 1.0547 - accuracy: 0.5795 - val_loss: 1.5943 - val_accuracy: 0.3955 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 25s 64ms/step - loss: 1.0344 - accuracy: 0.5890 - val_loss: 2.3898 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 26s 65ms/step - loss: 1.0171 - accuracy: 0.5973 - val_loss: 1.6685 - val_accuracy: 0.4147 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 23s 57ms/step - loss: 0.9990 - accuracy: 0.6023 - val_loss: 4.4156 - val_accuracy: 0.2818 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 23s 59ms/step - loss: 0.9816 - accuracy: 0.6102 - val_loss: 1.0183 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 21s 53ms/step - loss: 0.9618 - accuracy: 0.6171 - val_loss: 1.3697 - val_accuracy: 0.4847 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 24s 59ms/step - loss: 0.9371 - accuracy: 0.6307 - val_loss: 2.0202 - val_accuracy: 0.3860 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 25s 64ms/step - loss: 0.9186 - accuracy: 0.6375 - val_loss: 1.1635 - val_accuracy: 0.5490 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 0.9029 - accuracy: 0.6462 - val_loss: 0.9583 - val_accuracy: 0.6205 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 21s 53ms/step - loss: 0.8834 - accuracy: 0.6531 - val_loss: 1.4219 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 0.8617 - accuracy: 0.6628 - val_loss: 1.0991 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 0.8448 - accuracy: 0.6655 - val_loss: 2.4892 - val_accuracy: 0.3658 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 24s 61ms/step - loss: 0.8201 - accuracy: 0.6791 - val_loss: 2.1543 - val_accuracy: 0.4318 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 22s 54ms/step - loss: 0.8001 - accuracy: 0.6863 - val_loss: 0.9193 - val_accuracy: 0.6430 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 22s 54ms/step - loss: 0.7775 - accuracy: 0.6973 - val_loss: 3.7973 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 22s 55ms/step - loss: 0.7606 - accuracy: 0.7034 - val_loss: 0.8906 - val_accuracy: 0.6552 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 21s 54ms/step - loss: 0.7396 - accuracy: 0.7115 - val_loss: 0.9177 - val_accuracy: 0.6482 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 22s 54ms/step - loss: 0.7176 - accuracy: 0.7173 - val_loss: 0.9834 - val_accuracy: 0.6206 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 21s 54ms/step - loss: 0.6983 - accuracy: 0.7279 - val_loss: 2.0835 - val_accuracy: 0.5022 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 22s 54ms/step - loss: 0.6741 - accuracy: 0.7386 - val_loss: 2.6163 - val_accuracy: 0.4141 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 22s 55ms/step - loss: 0.6534 - accuracy: 0.7457 - val_loss: 1.1838 - val_accuracy: 0.6042 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 0.6324 - accuracy: 0.7532 - val_loss: 0.9283 - val_accuracy: 0.6584 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 25s 64ms/step - loss: 0.6203 - accuracy: 0.7605 - val_loss: 0.8835 - val_accuracy: 0.6794 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 25s 63ms/step - loss: 0.6021 - accuracy: 0.7694 - val_loss: 1.0885 - val_accuracy: 0.6415 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 25s 64ms/step - loss: 0.5847 - accuracy: 0.7726 - val_loss: 0.9902 - val_accuracy: 0.6535 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 24s 59ms/step - loss: 0.5638 - accuracy: 0.7835 - val_loss: 2.4889 - val_accuracy: 0.4812 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 21s 52ms/step - loss: 0.5495 - accuracy: 0.7891 - val_loss: 0.9729 - val_accuracy: 0.6614 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "389/398 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.7978"
     ]
    }
   ],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "checkpoint = CustomModelCheckpoint('best_weights_model_new.h5', save_best_only=True)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 7s 12ms/step - loss: 0.7337 - accuracy: 0.8205\n",
      "Test loss: 0.7336778044700623\n",
      "Test accuracy: 0.8204553723335266\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('best_weights_model.h5')\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
